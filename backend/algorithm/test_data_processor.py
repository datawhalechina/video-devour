# -*- coding: utf-8 -*-
"""
æµ‹è¯• ASRProcessor å¯¹æ–°æ ¼å¼ï¼ˆParaformer V2ï¼‰çš„å¤„ç†èƒ½åŠ›
"""
import json
import logging
from pathlib import Path
from data_processor import ASRProcessor

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

def test_paraformer_v2():
    """
    æµ‹è¯• Paraformer V2 æ ¼å¼çš„å¤„ç†
    """
    logging.info("="*60)
    logging.info("å¼€å§‹æµ‹è¯• Paraformer V2 æ ¼å¼å¤„ç†")
    logging.info("="*60)
    
    # è·å–é¡¹ç›®æ ¹ç›®å½•
    project_root = Path(__file__).resolve().parent.parent.parent
    
    # åŠ è½½ Paraformer V2 çš„ ASR ç»“æœ
    asr_file = project_root / "output" / "asr_results_paraformer_v2.json"
    
    if not asr_file.exists():
        logging.error(f"æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {asr_file}")
        return
    
    try:
        # åˆå§‹åŒ–å¤„ç†å™¨
        processor = ASRProcessor(str(asr_file))
        
        # å¤„ç†æ•°æ®
        chunked_dialogue = processor.process()
        
        # è¾“å‡ºç»“æœç»Ÿè®¡
        logging.info("\n" + "="*60)
        logging.info("å¤„ç†ç»“æœç»Ÿè®¡")
        logging.info("="*60)
        logging.info(f"æ€»åˆ†å—æ•°: {len(chunked_dialogue)}")
        
        # ç»Ÿè®¡è¯´è¯äºº
        speakers = set(item['speaker'] for item in chunked_dialogue)
        logging.info(f"è¯´è¯äººæ•°: {len(speakers)}")
        logging.info(f"è¯´è¯äººåˆ—è¡¨: {', '.join(sorted(speakers))}")
        
        # ç»Ÿè®¡æ¯ä¸ªè¯´è¯äººçš„åˆ†å—æ•°
        speaker_counts = {}
        for item in chunked_dialogue:
            speaker = item['speaker']
            speaker_counts[speaker] = speaker_counts.get(speaker, 0) + 1
        
        logging.info("\nå„è¯´è¯äººåˆ†å—ç»Ÿè®¡:")
        for speaker, count in sorted(speaker_counts.items()):
            logging.info(f"  {speaker}: {count} ä¸ªåˆ†å—")
        
        # è®¡ç®—æ€»æ—¶é•¿
        if chunked_dialogue:
            total_duration = chunked_dialogue[-1]['end'] - chunked_dialogue[0]['start']
            logging.info(f"\næ€»æ—¶é•¿: {total_duration:.2f} ç§’ ({total_duration/60:.2f} åˆ†é’Ÿ)")
        
        # æ˜¾ç¤ºå‰å‡ ä¸ªåˆ†å—ç¤ºä¾‹
        logging.info("\n" + "="*60)
        logging.info("å‰ 5 ä¸ªåˆ†å—ç¤ºä¾‹")
        logging.info("="*60)
        for i, chunk in enumerate(chunked_dialogue[:5], 1):
            logging.info(f"\nåˆ†å— {i}:")
            logging.info(f"  è¯´è¯äºº: {chunk['speaker']}")
            logging.info(f"  æ—¶é—´: {chunk['start']:.2f}s - {chunk['end']:.2f}s")
            logging.info(f"  æ—¶é•¿: {chunk['end'] - chunk['start']:.2f}s")
            logging.info(f"  æ–‡æœ¬é•¿åº¦: {len(chunk['text'])} å­—ç¬¦")
            logging.info(f"  æ–‡æœ¬: {chunk['text'][:100]}{'...' if len(chunk['text']) > 100 else ''}")
        
        # ä¿å­˜å¤„ç†ç»“æœ
        output_file = project_root / "output" / "processed_dialogue_v2.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(chunked_dialogue, f, ensure_ascii=False, indent=2)
        
        logging.info("\n" + "="*60)
        logging.info(f"âœ… å¤„ç†ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        logging.info("="*60)
        
    except Exception as e:
        logging.error(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False
    
    return True


def compare_chunk_quality(chunked_dialogue):
    """
    åˆ†æåˆ†å—è´¨é‡
    
    Args:
        chunked_dialogue (list[dict]): åˆ†å—å¯¹è¯åˆ—è¡¨
    """
    logging.info("\n" + "="*60)
    logging.info("åˆ†å—è´¨é‡åˆ†æ")
    logging.info("="*60)
    
    chunk_lengths = [len(chunk['text']) for chunk in chunked_dialogue]
    chunk_durations = [chunk['end'] - chunk['start'] for chunk in chunked_dialogue]
    
    logging.info(f"æ–‡æœ¬é•¿åº¦ç»Ÿè®¡:")
    logging.info(f"  å¹³å‡: {sum(chunk_lengths) / len(chunk_lengths):.1f} å­—ç¬¦")
    logging.info(f"  æœ€å°: {min(chunk_lengths)} å­—ç¬¦")
    logging.info(f"  æœ€å¤§: {max(chunk_lengths)} å­—ç¬¦")
    
    logging.info(f"\nåˆ†å—æ—¶é•¿ç»Ÿè®¡:")
    logging.info(f"  å¹³å‡: {sum(chunk_durations) / len(chunk_durations):.2f} ç§’")
    logging.info(f"  æœ€å°: {min(chunk_durations):.2f} ç§’")
    logging.info(f"  æœ€å¤§: {max(chunk_durations):.2f} ç§’")
    
    # åˆ†æè¿ç»­æ€§ï¼ˆæ£€æŸ¥æ—¶é—´é—´éš”ï¼‰
    gaps = []
    for i in range(1, len(chunked_dialogue)):
        gap = chunked_dialogue[i]['start'] - chunked_dialogue[i-1]['end']
        gaps.append(gap)
    
    if gaps:
        logging.info(f"\nåˆ†å—é—´éš”ç»Ÿè®¡:")
        logging.info(f"  å¹³å‡é—´éš”: {sum(gaps) / len(gaps):.2f} ç§’")
        logging.info(f"  æœ€å°é—´éš”: {min(gaps):.2f} ç§’")
        logging.info(f"  æœ€å¤§é—´éš”: {max(gaps):.2f} ç§’")
        
        # æ‰¾å‡ºå¼‚å¸¸å¤§çš„é—´éš”
        large_gaps = [(i+1, gap) for i, gap in enumerate(gaps) if gap > 5.0]
        if large_gaps:
            logging.info(f"\nå‘ç° {len(large_gaps)} ä¸ªå¤§é—´éš” (>5ç§’):")
            for idx, gap in large_gaps[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                logging.info(f"  åˆ†å— {idx} å: {gap:.2f} ç§’")


if __name__ == "__main__":
    logging.info("ğŸ§ª ASRProcessor æµ‹è¯•å¼€å§‹\n")
    
    success = test_paraformer_v2()
    
    if success:
        # è¯»å–å¤„ç†ç»“æœè¿›è¡Œè´¨é‡åˆ†æ
        project_root = Path(__file__).resolve().parent.parent.parent
        output_file = project_root / "output" / "processed_dialogue_v2.json"
        
        with open(output_file, 'r', encoding='utf-8') as f:
            chunked_dialogue = json.load(f)
        
        compare_chunk_quality(chunked_dialogue)
        
        logging.info("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    else:
        logging.error("\nâŒ æµ‹è¯•å¤±è´¥")

