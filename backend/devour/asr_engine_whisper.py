import whisperx
import torch
from pyannote.audio import Pipeline
from moviepy import VideoFileClip
import tempfile
import logging
import os
from pathlib import Path
import yaml
import json
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class VideoDevourASR:
    def __init__(self):
        config_file = Path(__file__).parent.parent.parent / 'config.yaml'
        if not config_file.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {config_file}")
        with open(config_file, 'r') as f:
            self.config = yaml.safe_load(f)

        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        logging.info(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        self._diarization_pipeline = None 
        self._whisper_model = None
        
    @property
    def whisper_model(self):
        if self._whisper_model is None:
            logging.info("æ­£åœ¨åŠ è½½Whisperæ¨¡å‹...")
            # åŠ è½½ä¼˜åŒ–çš„æ ‡ç‚¹ç¬¦å·é…ç½®
            default_asr_options = {
                "suppress_numerals": True,  # æŠ‘åˆ¶æ•°å­—è½¬å½•
                "suppress_tokens": [-1],    # æŠ‘åˆ¶ç‰¹å®štoken
                "without_timestamps": False,  # ä¿ç•™æ—¶é—´æˆ³
                "max_initial_timestamp": 10.0,  # æœ€å¤§åˆå§‹æ—¶é—´æˆ³
                "word_timestamps": True,    # å¯ç”¨è¯çº§æ—¶é—´æˆ³
                "prepend_punctuations": "\"'â€œÂ¿([{-",  # å‰ç½®æ ‡ç‚¹ç¬¦å·
                "append_punctuations": "\"'.ã€‚,ï¼Œ!ï¼?ï¼Ÿ:ï¼šâ€)]}ã€"  # åç½®æ ‡ç‚¹ç¬¦å·
            }
            
            # åŠ è½½WhisperXæ¨¡å‹ï¼Œä½¿ç”¨ä¼˜åŒ–é…ç½®
            self._whisper_model = whisperx.load_model(
                "large-v3", 
                self.device, 
                compute_type="float16" if self.device == "cuda" else "int8",
                asr_options=default_asr_options,
                vad_options={"vad_onset": 0.500, "vad_offset": 0.363},
                # æ·»åŠ æ ‡ç‚¹ç¬¦å·æ”¯æŒ
                language="zh",
                task="transcribe"
            )
            logging.info(f"Whisperæ¨¡å‹åŠ è½½å®Œæˆï¼ˆè®¾å¤‡: {self.device}ï¼‰")
        return self._whisper_model
        
    @property
    def diarization_pipeline(self):
        if self._diarization_pipeline is None:
            # ä¼˜å…ˆä»é…ç½®æ–‡ä»¶è¯»å–HF_TOKENï¼Œå…¶æ¬¡ä»ç¯å¢ƒå˜é‡è¯»å–
            hf_token = self.config.get('HF_TOKEN') or os.environ.get('HF_TOKEN')
            if not hf_token:
                logging.warning("HF_TOKENæœªè®¾ç½®ï¼Œè·³è¿‡è¯´è¯äººè¯†åˆ«")
                return None
                
            try:
                logging.info("æ­£åœ¨åŠ è½½è¯´è¯äººè¯†åˆ«æ¨¡å‹...")
                # é…ç½®è¯´è¯äººè¯†åˆ«å‚æ•°ä»¥ä¼˜åŒ–æ€§èƒ½
                self._diarization_pipeline = Pipeline.from_pretrained(
                    "pyannote/speaker-diarization-3.1",
                    use_auth_token=hf_token
                ).to(torch.device(self.device))
    
                logging.info(f"è¯´è¯äººè¯†åˆ«æ¨¡å‹åŠ è½½å®Œæˆï¼ˆè®¾å¤‡: {self.device}ï¼‰")
            except Exception as e:
                logging.error(f"è¯´è¯äººè¯†åˆ«æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
                logging.warning("è·³è¿‡è¯´è¯äººè¯†åˆ«ï¼Œç»§ç»­å¤„ç†")
                self._diarization_pipeline = None
                
        return self._diarization_pipeline
        
    def extract_audio(self, video_path: str) -> str:
        """æå–è§†é¢‘éŸ³é¢‘åˆ°ä¸´æ—¶wavæ–‡ä»¶"""
        logging.info(f"æ­£åœ¨æå–éŸ³é¢‘: {video_path}")
        try:
            with VideoFileClip(video_path) as video:
                audio = video.audio
                temp_wav = tempfile.NamedTemporaryFile(suffix=".wav", delete=False)
                audio.write_audiofile(temp_wav.name, codec="pcm_s16le", fps=16000)
                logging.info(f"éŸ³é¢‘æå–å®Œæˆ: {temp_wav.name}")
                return temp_wav.name
        except Exception as e:
            logging.error(f"éŸ³é¢‘æå–å¤±è´¥: {str(e)}")
            raise

    def devour_video(self, video_path: str) -> dict:
        """æ ¸å¿ƒåå™¬æ–¹æ³• - å¤„ç†å•ä¸ªè§†é¢‘"""
        logging.info(f"å¼€å§‹å¤„ç†è§†é¢‘: {video_path}")
        
        try:
            # éŸ³é¢‘æå–
            wav_path = self.extract_audio(video_path)
            
            # è¯­éŸ³è½¬å†™
            logging.info("å¼€å§‹è¯­éŸ³è½¬å†™...")
            audio = whisperx.load_audio(wav_path)
            
            # ä½¿ç”¨ä¼˜åŒ–çš„è½¬å½•å‚æ•°
            result = self.whisper_model.transcribe(
                audio, 
                batch_size=16, 
                language="zh",
                print_progress=True,  # æ˜¾ç¤ºè½¬å½•è¿›åº¦
                verbose=False  # ä¸æ˜¾ç¤ºè¯¦ç»†è¾“å‡ºï¼Œé¿å…æ—¥å¿—æ··ä¹±
            )
            
            language = result['language']
            logging.info(f"è½¬å†™å®Œæˆï¼Œæ£€æµ‹åˆ°è¯­è¨€: {language}")
            logging.info(f"è½¬å½•æ®µè½æ•°: {len(result.get('segments', []))}")
            
            # æ—¶é—´æˆ³å¯¹é½
            logging.info("å¼€å§‹æ—¶é—´æˆ³å¯¹é½...")
            model_a, metadata = whisperx.load_align_model(
                language_code=language,
                device=self.device
            )
            aligned_result = whisperx.align(
                result["segments"], model_a, metadata, audio, self.device
            )
            logging.info("æ—¶é—´æˆ³å¯¹é½å®Œæˆ")
            
            # è¯´è¯äººè¯†åˆ«ï¼ˆå¯é€‰ï¼‰
            diarization = None
            if self.diarization_pipeline is not None:
                logging.info("å¼€å§‹è¯´è¯äººè¯†åˆ«...")
                try:
                    # ä½¿ç”¨ä¼˜åŒ–å‚æ•°è¿›è¡Œè¯´è¯äººè¯†åˆ«
                    diarization = self.diarization_pipeline({"audio": wav_path}, min_speakers=1, max_speakers=10)
                    
                    # ç»Ÿè®¡è¯´è¯äººä¿¡æ¯
                    if diarization:
                        speakers = set()
                        for turn, _, speaker in diarization.itertracks(yield_label=True):
                            speakers.add(speaker)
                        logging.info(f"è¯´è¯äººè¯†åˆ«å®Œæˆ - æ£€æµ‹åˆ° {len(speakers)} ä½è¯´è¯äºº")
                    else:
                        logging.info("è¯´è¯äººè¯†åˆ«å®Œæˆ - æœªæ£€æµ‹åˆ°è¯´è¯äºº")
                        
                except Exception as e:
                    logging.warning(f"è¯´è¯äººè¯†åˆ«å¤±è´¥: {str(e)}")
                    logging.warning("ç»§ç»­å¤„ç†ï¼Œè·³è¿‡è¯´è¯äººè¯†åˆ«")
            else:
                logging.info("è·³è¿‡è¯´è¯äººè¯†åˆ«ï¼ˆæ— æœ‰æ•ˆHF_TOKENï¼‰")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.unlink(wav_path)
            except:
                pass
                
            return {
                "transcript": aligned_result["segments"],
                "speakers": diarization,
                "language": language,
                "video_path": video_path,
                "processed_at": datetime.now().isoformat()
            }
            
        except Exception as e:
            logging.error(f"ASRå¤„ç†å¤±è´¥: {str(e)}")
            # å°è¯•æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                if 'wav_path' in locals():
                    os.unlink(wav_path)
            except:
                pass
            raise

    def process_videos(self, video_dir: str) -> list:
        """æ‰¹é‡å¤„ç†è§†é¢‘ç›®å½•"""
        video_dir = Path(video_dir)
        if not video_dir.exists():
            raise FileNotFoundError(f"è§†é¢‘ç›®å½•ä¸å­˜åœ¨: {video_dir}")
            
        # æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶
        video_extensions = ['.mp4', '.mov', '.avi', '.mkv', '.wmv', '.flv', '.webm']
        video_files = []
        for ext in video_extensions:
            video_files.extend(video_dir.glob(f"*{ext}"))
            
        if not video_files:
            raise FileNotFoundError(f"æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶: {video_dir}")
            
        logging.info(f"æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
        
        results = []
        for video_file in video_files:
            try:
                result = self.devour_video(str(video_file))
                results.append(result)
                logging.info(f"âœ… å®Œæˆ: {video_file.name}")
            except Exception as e:
                logging.error(f"âŒ å¤±è´¥: {video_file.name} - {str(e)}")
                continue
                
        return results
        
    def save_results(self, results: list, output_file: str):
        """ä¿å­˜å¤„ç†ç»“æœåˆ°JSONæ–‡ä»¶"""
        # è½¬æ¢speakerså¯¹è±¡ä¸ºå¯åºåˆ—åŒ–æ ¼å¼
        for result in results:
            if 'speakers' in result and result['speakers'] is not None:
                # æå–è¯´è¯äººæ—¶é—´è½´ä¿¡æ¯ä¸ºç»“æ„åŒ–æ•°æ®
                speakers_data = []
                try:
                    for turn, _, speaker in result['speakers'].itertracks(yield_label=True):
                        speakers_data.append({
                            "speaker": speaker,
                            "start": float(turn.start),
                            "end": float(turn.end),
                            "duration": float(turn.end - turn.start)
                        })
                    result['speakers'] = speakers_data
                except Exception as e:
                    logging.warning(f"è¯´è¯äººæ•°æ®è½¬æ¢å¤±è´¥: {str(e)}")
                    result['speakers'] = str(result['speakers'])
            
            # ç»Ÿè®¡è½¬å½•æ–‡æœ¬è´¨é‡æŒ‡æ ‡
            if 'transcript' in result and result['transcript']:
                total_text = " ".join([segment.get('text', '') for segment in result['transcript']])
                result['text_stats'] = {
                    "total_segments": len(result['transcript']),
                    "total_words": len(total_text.split()),
                    "total_chars": len(total_text),
                    "avg_segment_duration": sum([seg.get('end', 0) - seg.get('start', 0) for seg in result['transcript']]) / len(result['transcript']) if result['transcript'] else 0
                }
                
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        logging.info(f"ç»“æœå·²ä¿å­˜åˆ°: {output_file}")


if __name__ == "__main__":
    # æµ‹è¯•ASRå¼•æ“
    logging.info("ğŸ½ï¸ VideoDevour ASR å¼•æ“æµ‹è¯•å¼€å§‹")
    
    try:
        # åˆå§‹åŒ–ASRå¼•æ“
        asr = VideoDevourASR()
        
        # å¤„ç†è§†é¢‘ç›®å½•
        video_dir = "/home/hesper/project/VideoDevour/video"
        results = asr.process_videos(video_dir)
        
        # ä¿å­˜ç»“æœ
        output_file = "/home/hesper/project/VideoDevour/datafactory/asr_results_whisper.json"
        asr.save_results(results, output_file)
        
        # æ‰“å°æ‘˜è¦
        logging.info(f"\nğŸ“Š å¤„ç†æ‘˜è¦:")
        logging.info(f"âœ… æˆåŠŸå¤„ç†: {len(results)} ä¸ªè§†é¢‘")
        
        total_segments = 0
        total_words = 0
        total_chars = 0
        
        for i, result in enumerate(results, 1):
            logging.info(f"  {i}. {Path(result['video_path']).name}")
            logging.info(f"     è¯­è¨€: {result['language']}")
            logging.info(f"     æ®µè½æ•°: {len(result['transcript'])}")
            
            # ç»Ÿè®¡æ–‡æœ¬ä¿¡æ¯
            if 'text_stats' in result:
                stats = result['text_stats']
                total_segments += stats['total_segments']
                total_words += stats['total_words'] 
                total_chars += stats['total_chars']
                logging.info(f"     å­—æ•°: {stats['total_words']}, å­—ç¬¦æ•°: {stats['total_chars']}")
            
            # è¯´è¯äººä¿¡æ¯
            if result.get('speakers'):
                if isinstance(result['speakers'], list):
                    unique_speakers = len(set(s['speaker'] for s in result['speakers']))
                    logging.info(f"     è¯´è¯äºº: {unique_speakers} ä½")
                else:
                    logging.info(f"     è¯´è¯äºº: æ•°æ®å¯ç”¨")
        
        # æ€»ä½“ç»Ÿè®¡
        if total_segments > 0:
            logging.info(f"\nğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
            logging.info(f"     æ€»æ®µè½æ•°: {total_segments}")
            logging.info(f"     æ€»å­—æ•°: {total_words}")
            logging.info(f"     æ€»å­—ç¬¦æ•°: {total_chars}")
            logging.info(f"     å¹³å‡æ®µè½é•¿åº¦: {total_chars/total_segments:.1f} å­—ç¬¦")
            
    except Exception as e:
        logging.error(f"æµ‹è¯•å¤±è´¥: {str(e)}")
        exit(1)
        
    logging.info("\nğŸ‰ ASRå¼•æ“æµ‹è¯•å®Œæˆï¼")