import torch
from pyannote.audio import Pipeline
from moviepy import VideoFileClip
import tempfile
import logging
import os
from pathlib import Path
import yaml
import json
from datetime import datetime
from funasr import AutoModel
from funasr.utils.postprocess_utils import rich_transcription_postprocess
import soundfile as sf  # ç”¨äºè¯»å–å’Œè£å‰ªéŸ³é¢‘æ–‡ä»¶
import sys

# æ·»åŠ ç®—æ³•æ¨¡å—è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent / "algorithm"))
from modelscope_manager import ModelScopeManager

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class VideoDevourASRFunasr:
    def __init__(self):
        config_file = Path(__file__).parent.parent.parent / 'config.yaml'
        if not config_file.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {config_file}")
        with open(config_file, 'r') as f:
            self.config = yaml.safe_load(f)

        # SenseVoice æ¨èä½¿ç”¨ "cuda:0" æ ¼å¼
        self.device = "cuda:0" if torch.cuda.is_available() else "cpu"
        logging.info(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        self._diarization_pipeline = None 
        self._asr_model = None
        self._vad_model = None  # VAD æ¨¡å‹å•ç‹¬åŠ è½½
        
        # è·å–é¡¹ç›®æ ¹ç›®å½•
        self.project_root = Path(__file__).resolve().parent.parent.parent
        
        # åˆå§‹åŒ– ModelScope ç®¡ç†å™¨
        self.model_manager = ModelScopeManager(str(self.project_root))
        
        # è‡ªåŠ¨æ£€æŸ¥å’Œä¸‹è½½ç¼ºå¤±çš„æ¨¡å‹
        self._ensure_models_available()
    
    def _ensure_models_available(self):
        """
        ç¡®ä¿æ‰€éœ€çš„æ¨¡å‹éƒ½å¯ç”¨ï¼Œå¦‚æœç¼ºå¤±åˆ™è‡ªåŠ¨ä¸‹è½½
        """
        try:
            missing_models = self.model_manager.get_missing_models()
            
            if missing_models:
                logging.info(f"æ£€æµ‹åˆ°ç¼ºå¤±æ¨¡å‹: {missing_models}")
                logging.info("æ­£åœ¨è‡ªåŠ¨ä¸‹è½½ç¼ºå¤±çš„æ¨¡å‹...")
                
                # ä¸‹è½½ç¼ºå¤±çš„æ¨¡å‹
                results = self.model_manager.download_all_missing_models()
                
                # æ£€æŸ¥ä¸‹è½½ç»“æœ
                failed_models = [model for model, success in results.items() if not success]
                if failed_models:
                    logging.warning(f"ä»¥ä¸‹æ¨¡å‹ä¸‹è½½å¤±è´¥: {failed_models}")
                    logging.warning("å°†ä½¿ç”¨è¿œç¨‹æ¨¡å‹ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ")
                else:
                    logging.info("æ‰€æœ‰ç¼ºå¤±æ¨¡å‹ä¸‹è½½å®Œæˆ")
            else:
                logging.info("æ‰€æœ‰å¿…éœ€æ¨¡å‹éƒ½å·²å­˜åœ¨")
                
        except Exception as e:
            logging.warning(f"æ¨¡å‹æ£€æŸ¥è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            logging.warning("å°†ä½¿ç”¨è¿œç¨‹æ¨¡å‹ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ")
        
    @property
    def vad_model(self):
        """åŠ è½½ VAD æ¨¡å‹ï¼ˆç”¨äºéŸ³é¢‘åˆ†æ®µï¼‰"""
        if self._vad_model is None:
            logging.info("æ­£åœ¨åŠ è½½ VAD æ¨¡å‹...")
            try:
                self._vad_model = AutoModel(
                    model="fsmn-vad",
                    trust_remote_code=True,
                    device=self.device,
                    disable_update=True,
                )
                logging.info(f"VAD æ¨¡å‹åŠ è½½å®Œæˆï¼ˆè®¾å¤‡: {self.device}ï¼‰")
            except Exception as e:
                logging.error(f"VAD æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
                raise
        return self._vad_model
    
    @property
    def asr_model(self):
        """åŠ è½½ SenseVoice æ¨¡å‹ï¼ˆä¸åŒ…å« VADï¼‰"""
        if self._asr_model is None:
            logging.info("æ­£åœ¨åŠ è½½æœ¬åœ° SenseVoice æ¨¡å‹...")
            # åŠ¨æ€æ„å»ºæ¨¡å‹çš„æœ¬åœ°è·¯å¾„ï¼Œå¢å¼ºä»£ç å¯ç§»æ¤æ€§
            project_root = Path(__file__).resolve().parent.parent.parent
            model_path = project_root / "models/models/iic/SenseVoiceSmall"
            
            if not model_path.exists():
                logging.warning(f"æœ¬åœ°SenseVoiceæ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}ï¼Œå°†ä»è¿œç¨‹åŠ è½½")
                # å¦‚æœæœ¬åœ°æ¨¡å‹ä¸å­˜åœ¨ï¼Œä½¿ç”¨è¿œç¨‹æ¨¡å‹
                model_dir = "iic/SenseVoiceSmall"
            else:
                model_dir = str(model_path)

            # åŠ è½½SenseVoiceæ¨¡å‹ï¼ˆä¸åŒ…å« VADï¼Œå› ä¸º VAD å•ç‹¬å¤„ç†ï¼‰
            self._asr_model = AutoModel(
                model=model_dir,
                trust_remote_code=True,
                device=self.device,
                disable_update=True,
                # spk_model="cam++",
            )
            logging.info(f"SenseVoice æ¨¡å‹åŠ è½½å®Œæˆï¼ˆè®¾å¤‡: {self.device}ï¼‰")
        return self._asr_model
        
    @property
    def diarization_pipeline(self):
        """è¯´è¯äººè¯†åˆ«ç®¡é“ï¼ˆå¯é€‰ï¼‰"""
        project_root = Path(__file__).resolve().parent.parent.parent
        vad_model_path = project_root / "models/models/iic/speech_fsmn_vad_zh-cn-16k-common-pytorch"
        paraformer_model_path = project_root / "models/models/iic/speech_paraformer-large-vad-punc-spk_asr_nat-zh-cn"
        punc_model_path = project_root / "models/models/iic/punc_ct-transformer_cn-en-common-vocab471067-large"
        if self._diarization_pipeline is None:
            try:
                logging.info("æ­£åœ¨åŠ è½½è¯´è¯äººè¯†åˆ«æ¨¡å‹...")
                # é…ç½®è¯´è¯äººè¯†åˆ«å‚æ•°ä»¥ä¼˜åŒ–æ€§èƒ½
                self._diarization_pipeline = AutoModel(
                    model="cam++",
                    vad_model=str(vad_model_path),
                    vad_kwargs={"max_single_segment_time": 30000},
                    punc_model=str(punc_model_path),
                    device=self.device,
                )
    
                logging.info(f"è¯´è¯äººè¯†åˆ«æ¨¡å‹åŠ è½½å®Œæˆï¼ˆè®¾å¤‡: {self.device}ï¼‰")
            except Exception as e:
                logging.error(f"è¯´è¯äººè¯†åˆ«æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
                logging.warning("è·³è¿‡è¯´è¯äººè¯†åˆ«ï¼Œç»§ç»­å¤„ç†")
                self._diarization_pipeline = None
                
        return self._diarization_pipeline
        
    def extract_audio(self, video_path: str) -> str:
        """æå–è§†é¢‘éŸ³é¢‘åˆ°ä¸´æ—¶wavæ–‡ä»¶"""
        logging.info(f"æ­£åœ¨æå–éŸ³é¢‘: {video_path}")
        try:
            with VideoFileClip(video_path) as video:
                audio = video.audio
                temp_wav = tempfile.NamedTemporaryFile(suffix=".wav", delete=False)
                audio.write_audiofile(temp_wav.name, codec="pcm_s16le", fps=16000)
                logging.info(f"éŸ³é¢‘æå–å®Œæˆ: {temp_wav.name}")
                return temp_wav.name
        except Exception as e:
            logging.error(f"éŸ³é¢‘æå–å¤±è´¥: {str(e)}")
            raise
    
    def crop_audio(self, audio_data, start_time, end_time, sample_rate):
        """
        è£å‰ªéŸ³é¢‘ç‰‡æ®µ
        
        Args:
            audio_data: éŸ³é¢‘æ•°æ®æ•°ç»„
            start_time: å¼€å§‹æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
            end_time: ç»“æŸæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
            sample_rate: é‡‡æ ·ç‡
            
        Returns:
            è£å‰ªåçš„éŸ³é¢‘æ•°æ®
        """
        start_sample = int(start_time * sample_rate / 1000)  # è½¬æ¢ä¸ºæ ·æœ¬æ•°
        end_sample = int(end_time * sample_rate / 1000)  # è½¬æ¢ä¸ºæ ·æœ¬æ•°
        return audio_data[start_sample:end_sample]

    def devour_video(self, video_path: str) -> dict:
        """æ ¸å¿ƒåå™¬æ–¹æ³• - ä½¿ç”¨ä¸¤é˜¶æ®µè¯†åˆ«ï¼ˆVADåˆ†æ®µ + SenseVoiceè¯†åˆ«ï¼‰"""
        logging.info(f"å¼€å§‹å¤„ç†è§†é¢‘: {video_path}")
        
        try:
            # éŸ³é¢‘æå–
            wav_path = self.extract_audio(video_path)
            
            # ç¬¬ä¸€é˜¶æ®µï¼šä½¿ç”¨ VAD æ¨¡å‹è¿›è¡ŒéŸ³é¢‘åˆ†æ®µ
            logging.info("ç¬¬ä¸€é˜¶æ®µï¼šä½¿ç”¨ VAD æ¨¡å‹è¿›è¡ŒéŸ³é¢‘åˆ†æ®µ...")
            vad_res = self.vad_model.generate(
                input=wav_path,
                cache={},
                max_single_segment_time=30000,  # æœ€å¤§å•ä¸ªç‰‡æ®µæ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
            )
            
            # ä» VAD æ¨¡å‹çš„è¾“å‡ºä¸­æå–æ¯ä¸ªè¯­éŸ³ç‰‡æ®µçš„å¼€å§‹å’Œç»“æŸæ—¶é—´
            if not vad_res or len(vad_res) == 0:
                logging.error("VAD æ¨¡å‹æœªè¿”å›æœ‰æ•ˆç»“æœ")
                raise ValueError("VAD åˆ†æ®µå¤±è´¥")
            
            segments_vad = vad_res[0].get('value', [])
            logging.info(f"VAD æ£€æµ‹åˆ° {len(segments_vad)} ä¸ªè¯­éŸ³ç‰‡æ®µ")
            
            # åŠ è½½åŸå§‹éŸ³é¢‘æ•°æ®
            audio_data, sample_rate = sf.read(wav_path)
            logging.info(f"éŸ³é¢‘é‡‡æ ·ç‡: {sample_rate} Hz")
            
            # ç¬¬äºŒé˜¶æ®µï¼šå¯¹æ¯ä¸ª VAD ç‰‡æ®µä½¿ç”¨ SenseVoice è¿›è¡Œè¯†åˆ«
            logging.info("ç¬¬äºŒé˜¶æ®µï¼šä½¿ç”¨ SenseVoice å¯¹æ¯ä¸ªç‰‡æ®µè¿›è¡Œè¯†åˆ«...")
            segments = []
            temp_audio_file = None
            
            for i, segment in enumerate(segments_vad):
                start_time, end_time = segment  # è·å–å¼€å§‹å’Œç»“æŸæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
                
                # è£å‰ªéŸ³é¢‘
                cropped_audio = self.crop_audio(audio_data, start_time, end_time, sample_rate)
                
                # å°†è£å‰ªåçš„éŸ³é¢‘ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
                temp_audio_file = tempfile.NamedTemporaryFile(suffix=".wav", delete=False).name
                sf.write(temp_audio_file, cropped_audio, sample_rate)
                
                try:
                    # ä½¿ç”¨ SenseVoice è¿›è¡Œè¯­éŸ³è¯†åˆ«
                    res = self.asr_model.generate(
                        input=temp_audio_file,
                        cache={},
                        language="auto",  # "zh", "en", "yue", "ja", "ko", "nospeech"
                        use_itn=True,  # ä½¿ç”¨é€†æ–‡æœ¬è§„èŒƒåŒ–
                        batch_size_s=60,
                    )
                    
                    # å¤„ç†è¯†åˆ«ç»“æœ
                    if isinstance(res, list) and len(res) > 0 and "text" in res[0]:
                        text = rich_transcription_postprocess(res[0]["text"])
                        print(res)
                        # æ·»åŠ æ—¶é—´æˆ³ï¼ˆè½¬æ¢ä¸ºç§’ï¼‰
                        segments.append({
                            "id": i,
                            "start": start_time / 1000.0,  # æ¯«ç§’è½¬ç§’
                            "end": end_time / 1000.0,      # æ¯«ç§’è½¬ç§’
                            "text": text.strip()
                        })
                        
                        logging.info(f"  ç‰‡æ®µ {i+1}/{len(segments_vad)}: {start_time/1000:.1f}s - {end_time/1000:.1f}s, æ–‡æœ¬é•¿åº¦: {len(text)}")
                    else:
                        logging.warning(f"  ç‰‡æ®µ {i+1} è¯†åˆ«ç»“æœä¸ºç©º")
                        
                except Exception as e:
                    logging.warning(f"  ç‰‡æ®µ {i+1} è¯†åˆ«å¤±è´¥: {str(e)}")
                    continue
                finally:
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    if temp_audio_file and os.path.exists(temp_audio_file):
                        try:
                            os.unlink(temp_audio_file)
                        except:
                            pass
            
            # æ£€æµ‹è¯­è¨€ï¼ˆä»ç¬¬ä¸€ä¸ªæœ‰æ•ˆç»“æœä¸­è·å–ï¼‰
            language = "auto"
            if segments:
                logging.info(f"è½¬å†™å®Œæˆï¼Œå…±è¯†åˆ« {len(segments)} ä¸ªæœ‰æ•ˆç‰‡æ®µ")
            else:
                logging.warning("æœªè¯†åˆ«åˆ°ä»»ä½•æœ‰æ•ˆç‰‡æ®µ")
            
            # è¯´è¯äººè¯†åˆ«ï¼ˆå¯é€‰ï¼‰
            diarization = None
            if self.diarization_pipeline is not None:
                logging.info("å¼€å§‹è¯´è¯äººè¯†åˆ«...")
                try:
                    # ä½¿ç”¨æ–°çš„Paraformeræ¨¡å‹è¿›è¡Œè¯´è¯äººè¯†åˆ«
                    diarization_result = self.diarization_pipeline.generate(input=wav_path, batch_size_s=60, batch_size_threshold_s=60)
                    
                    # å¤„ç†è¯†åˆ«ç»“æœ
                    if diarization_result and len(diarization_result) > 0:
                        diarization = diarization_result[0] if "spk_segment" in diarization_result[0] else None
                        if diarization:
                            logging.info("è¯´è¯äººè¯†åˆ«å®Œæˆ")
                        else:
                            logging.info("è¯´è¯äººè¯†åˆ«å®Œæˆ - æœªæ£€æµ‹åˆ°è¯´è¯äºº")
                    else:
                        logging.info("è¯´è¯äººè¯†åˆ«å®Œæˆ - æœªæ£€æµ‹åˆ°è¯´è¯äºº")
                        
                except Exception as e:
                    logging.warning(f"è¯´è¯äººè¯†åˆ«å¤±è´¥: {str(e)}")
                    logging.warning("ç»§ç»­å¤„ç†ï¼Œè·³è¿‡è¯´è¯äººè¯†åˆ«")
            else:
                logging.info("è·³è¿‡è¯´è¯äººè¯†åˆ«ï¼ˆæ¨¡å‹æœªåŠ è½½ï¼‰")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.unlink(wav_path)
            except:
                pass
                
            return {
                "transcript": segments,
                "speakers": diarization,
                "language": language,
                "video_path": video_path,
                "processed_at": datetime.now().isoformat()
            }
            
        except Exception as e:
            logging.error(f"ASRå¤„ç†å¤±è´¥: {str(e)}")
            # å°è¯•æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                if 'wav_path' in locals():
                    os.unlink(wav_path)
            except:
                pass
            raise

    def process_videos(self, video_dir: str) -> list:
        """æ‰¹é‡å¤„ç†è§†é¢‘ç›®å½•"""
        video_dir = Path(video_dir)
        if not video_dir.exists():
            raise FileNotFoundError(f"è§†é¢‘ç›®å½•ä¸å­˜åœ¨: {video_dir}")
            
        # æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶
        video_extensions = ['.mp4', '.mov', '.avi', '.mkv', '.wmv', '.flv', '.webm']
        video_files = []
        for ext in video_extensions:
            video_files.extend(video_dir.glob(f"*{ext}"))
            
        if not video_files:
            raise FileNotFoundError(f"æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶: {video_dir}")
            
        logging.info(f"æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
        
        results = []
        for video_file in video_files:
            try:
                result = self.devour_video(str(video_file))
                results.append(result)
                logging.info(f"âœ… å®Œæˆ: {video_file.name}")
            except Exception as e:
                logging.error(f"âŒ å¤±è´¥: {video_file.name} - {str(e)}")
                continue
                
        return results
        
    def save_results(self, results: list, output_file: str):
        """ä¿å­˜å¤„ç†ç»“æœåˆ°JSONæ–‡ä»¶"""
        # è½¬æ¢speakerså¯¹è±¡ä¸ºå¯åºåˆ—åŒ–æ ¼å¼
        for result in results:
            if 'speakers' in result and result['speakers'] is not None:
                # å¤„ç†æ–°çš„Paraformeræ¨¡å‹çš„è¯´è¯äººè¯†åˆ«ç»“æœ
                if isinstance(result['speakers'], dict) and 'spk_segment' in result['speakers']:
                    speakers_data = []
                    try:
                        # å¤„ç†è¯´è¯äººåˆ†æ®µä¿¡æ¯
                        for segment in result['speakers']['spk_segment']:
                            speakers_data.append({
                                "speaker": segment.get('spk', 'UNKNOWN'),
                                "start": float(segment.get('start', 0)),
                                "end": float(segment.get('end', 0)),
                                "duration": float(segment.get('end', 0) - segment.get('start', 0))
                            })
                        result['speakers'] = speakers_data
                    except Exception as e:
                        logging.warning(f"è¯´è¯äººæ•°æ®è½¬æ¢å¤±è´¥: {str(e)}")
                        result['speakers'] = str(result['speakers'])
                # ä¿æŒå¯¹æ—§æ ¼å¼çš„å…¼å®¹æ€§
                elif hasattr(result['speakers'], 'itertracks'):
                    # æå–è¯´è¯äººæ—¶é—´è½´ä¿¡æ¯ä¸ºç»“æ„åŒ–æ•°æ®
                    speakers_data = []
                    try:
                        for turn, _, speaker in result['speakers'].itertracks(yield_label=True):
                            speakers_data.append({
                                "speaker": speaker,
                                "start": float(turn.start),
                                "end": float(turn.end),
                                "duration": float(turn.end - turn.start)
                            })
                        result['speakers'] = speakers_data
                    except Exception as e:
                        logging.warning(f"è¯´è¯äººæ•°æ®è½¬æ¢å¤±è´¥: {str(e)}")
                        result['speakers'] = str(result['speakers'])
                else:
                    # å¦‚æœæ˜¯å…¶ä»–æ ¼å¼ï¼Œç›´æ¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                    result['speakers'] = str(result['speakers'])
            
            # ç»Ÿè®¡è½¬å½•æ–‡æœ¬è´¨é‡æŒ‡æ ‡
            if 'transcript' in result and result['transcript']:
                total_text = " ".join([segment.get('text', '') for segment in result['transcript']])
                result['text_stats'] = {
                    "total_segments": len(result['transcript']),
                    "total_words": len(total_text.split()),
                    "total_chars": len(total_text),
                    "avg_segment_duration": sum([seg.get('end', 0) - seg.get('start', 0) for seg in result['transcript']]) / len(result['transcript']) if result['transcript'] else 0
                }
                
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        logging.info(f"ç»“æœå·²ä¿å­˜åˆ°: {output_file}")


if __name__ == "__main__":
    # æµ‹è¯•ASRå¼•æ“
    logging.info("ğŸ½ï¸ VideoDevour ASR Funasrå¼•æ“æµ‹è¯•å¼€å§‹")
    
    try:
        # åˆå§‹åŒ–ASRå¼•æ“
        asr = VideoDevourASRFunasr()
        
        # å¤„ç†è§†é¢‘ç›®å½•
        # Get the project root directory (assuming this file is in backend/devour)
        project_root = Path(__file__).resolve().parent.parent.parent
        video_dir = project_root / "input_video"
        results = asr.process_videos(str(video_dir))
        
        # ä¿å­˜ç»“æœ
        output_file = project_root / "output" / "asr_results_sensevoice.json"
        output_file.parent.mkdir(parents=True, exist_ok=True)
        asr.save_results(results, str(output_file))
        
        # æ‰“å°æ‘˜è¦
        logging.info(f"\nğŸ“Š å¤„ç†æ‘˜è¦:")
        logging.info(f"âœ… æˆåŠŸå¤„ç†: {len(results)} ä¸ªè§†é¢‘")
        
        total_segments = 0
        total_words = 0
        total_chars = 0
        
        for i, result in enumerate(results, 1):
            logging.info(f"  {i}. {Path(result['video_path']).name}")
            logging.info(f"     è¯­è¨€: {result['language']}")
            logging.info(f"     æ®µè½æ•°: {len(result['transcript'])}")
            
            # ç»Ÿè®¡æ–‡æœ¬ä¿¡æ¯
            if 'text_stats' in result:
                stats = result['text_stats']
                total_segments += stats['total_segments']
                total_words += stats['total_words'] 
                total_chars += stats['total_chars']
                logging.info(f"     å­—æ•°: {stats['total_words']}, å­—ç¬¦æ•°: {stats['total_chars']}")
            
            # è¯´è¯äººä¿¡æ¯
            if result.get('speakers'):
                if isinstance(result['speakers'], list):
                    unique_speakers = len(set(s['speaker'] for s in result['speakers']))
                    logging.info(f"     è¯´è¯äºº: {unique_speakers} ä½")
                else:
                    logging.info(f"     è¯´è¯äºº: æ•°æ®å¯ç”¨")
        
        # æ€»ä½“ç»Ÿè®¡
        if total_segments > 0:
            logging.info(f"\nğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
            logging.info(f"     æ€»æ®µè½æ•°: {total_segments}")
            logging.info(f"     æ€»å­—æ•°: {total_words}")
            logging.info(f"     æ€»å­—ç¬¦æ•°: {total_chars}")
            logging.info(f"     å¹³å‡æ®µè½é•¿åº¦: {total_chars/total_segments:.1f} å­—ç¬¦")
            
    except Exception as e:
        logging.error(f"æµ‹è¯•å¤±è´¥: {str(e)}")
        exit(1)