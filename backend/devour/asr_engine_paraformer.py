import torch
from pyannote.audio import Pipeline
from moviepy import VideoFileClip
import tempfile
import logging
import os
from pathlib import Path
import yaml
import json
from datetime import datetime
from funasr import AutoModel
from funasr.utils.postprocess_utils import rich_transcription_postprocess

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class VideoDevourASRFunasr:
    def __init__(self):
        config_file = Path(__file__).parent.parent.parent / 'config.yaml'
        if not config_file.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {config_file}")
        with open(config_file, 'r') as f:
            self.config = yaml.safe_load(f)

        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        logging.info(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        self._diarization_pipeline = None 
        self._asr_model = None
        
    @property
    def asr_model(self):
        if self._asr_model is None:
            logging.info("æ­£åœ¨åŠ è½½æœ¬åœ°Paraformeræ¨¡å‹...")
            # åŠ¨æ€æ„å»ºæ¨¡å‹çš„æœ¬åœ°è·¯å¾„ï¼Œå¢å¼ºä»£ç å¯ç§»æ¤æ€§
            project_root = Path(__file__).resolve().parent.parent.parent
            model_path = project_root / "models/models/iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch"
            vad_model_path = project_root / "models/models/iic/speech_fsmn_vad_zh-cn-16k-common-pytorch"
            punc_model_path = project_root / "models/models/iic/punc_ct-transformer_cn-en-common-vocab471067-large"
            paraformer_model_path = project_root / "models/models/iic/speech_paraformer-large-vad-punc-spk_asr_nat-zh-cn"
            if not model_path.exists():
                logging.error(f"ASRæ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
                raise FileNotFoundError(f"æŒ‡å®šçš„ASRæ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
            if not vad_model_path.exists():
                logging.error(f"VADæ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {vad_model_path}")
                raise FileNotFoundError(f"æŒ‡å®šçš„VADæ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {vad_model_path}")
            if not punc_model_path.exists():
                logging.error(f"PUNCæ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {punc_model_path}")
                raise FileNotFoundError(f"æŒ‡å®šçš„PUNCæ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {punc_model_path}")

            # åŠ è½½Paraformeræ¨¡å‹
            self._asr_model = AutoModel(
                model=str(model_path),
                vad_model=str(vad_model_path),
                vad_kwargs={"max_single_segment_time": 30000},
                punc_model=str(punc_model_path),
                device=self.device,
                disable_update=True,
            )
            logging.info(f"Paraformeræ¨¡å‹åŠ è½½å®Œæˆï¼ˆè®¾å¤‡: {self.device}ï¼‰")
        return self._asr_model
        
    @property
    def diarization_pipeline(self):
        vad_model_path = project_root / "models/models/iic/speech_fsmn_vad_zh-cn-16k-common-pytorch"
        paraformer_model_path = project_root / "models/models/iic/speech_paraformer-large-vad-punc-spk_asr_nat-zh-cn"
        punc_model_path = project_root / "models/models/iic/punc_ct-transformer_cn-en-common-vocab471067-large"
        if self._diarization_pipeline is None:
            # ä¼˜å…ˆä»é…ç½®æ–‡ä»¶è¯»å–HF_TOKENï¼Œå…¶æ¬¡ä»ç¯å¢ƒå˜é‡è¯»å–
            hf_token = self.config.get('HF_TOKEN') or os.environ.get('HF_TOKEN')
            if not hf_token:
                logging.warning("HF_TOKENæœªè®¾ç½®ï¼Œè·³è¿‡è¯´è¯äººè¯†åˆ«")
                return None
                
            try:
                logging.info("æ­£åœ¨åŠ è½½è¯´è¯äººè¯†åˆ«æ¨¡å‹...")
                # é…ç½®è¯´è¯äººè¯†åˆ«å‚æ•°ä»¥ä¼˜åŒ–æ€§èƒ½
                self._diarization_pipeline = AutoModel(
                    model=str(paraformer_model_path),
                    vad_model=str(vad_model_path),
                    vad_kwargs={"max_single_segment_time": 30000},
                    punc_model=str(punc_model_path),
                    device=self.device,
                )
    
                logging.info(f"è¯´è¯äººè¯†åˆ«æ¨¡å‹åŠ è½½å®Œæˆï¼ˆè®¾å¤‡: {self.device}ï¼‰")
            except Exception as e:
                logging.error(f"è¯´è¯äººè¯†åˆ«æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
                logging.warning("è·³è¿‡è¯´è¯äººè¯†åˆ«ï¼Œç»§ç»­å¤„ç†")
                self._diarization_pipeline = None
                
        return self._diarization_pipeline
        
    def extract_audio(self, video_path: str) -> str:
        """æå–è§†é¢‘éŸ³é¢‘åˆ°ä¸´æ—¶wavæ–‡ä»¶"""
        logging.info(f"æ­£åœ¨æå–éŸ³é¢‘: {video_path}")
        try:
            with VideoFileClip(video_path) as video:
                audio = video.audio
                temp_wav = tempfile.NamedTemporaryFile(suffix=".wav", delete=False)
                audio.write_audiofile(temp_wav.name, codec="pcm_s16le", fps=16000)
                logging.info(f"éŸ³é¢‘æå–å®Œæˆ: {temp_wav.name}")
                return temp_wav.name
        except Exception as e:
            logging.error(f"éŸ³é¢‘æå–å¤±è´¥: {str(e)}")
            raise

    def devour_video(self, video_path: str) -> dict:
        """æ ¸å¿ƒåå™¬æ–¹æ³• - å¤„ç†å•ä¸ªè§†é¢‘"""
        logging.info(f"å¼€å§‹å¤„ç†è§†é¢‘: {video_path}")
        
        try:
            # éŸ³é¢‘æå–
            wav_path = self.extract_audio(video_path)
            
            # è¯­éŸ³è½¬å†™
            logging.info("å¼€å§‹è¯­éŸ³è½¬å†™...")
            
            # ä½¿ç”¨Paraformerè¿›è¡Œè¯­éŸ³è¯†åˆ«
            res = self.asr_model.generate(
                input=wav_path,
                batch_size_s=60,
                batch_size_threshold_s=60,
                merge_vad=True,
                merge_length_s=15,
            )
            
            # å¤„ç†ç»“æœ
            if isinstance(res, list) and len(res) > 0:
                text = rich_transcription_postprocess(res[0]["text"])
                segments = []
                # å¦‚æœç»“æœåŒ…å«æ—¶é—´æˆ³ä¿¡æ¯
                if "timestamp" in res[0]:
                    for i, (start, end) in enumerate(res[0]["timestamp"]):
                        segments.append({
                            "id": i,
                            "start": start / 1000.0,  # è½¬æ¢ä¸ºç§’
                            "end": end / 1000.0,      # è½¬æ¢ä¸ºç§’
                            "text": res[0]["text"].split()[i] if i < len(res[0]["text"].split()) else ""
                        })
                else:
                    # å¦‚æœæ²¡æœ‰æ—¶é—´æˆ³ä¿¡æ¯ï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„æ®µè½
                    segments.append({
                        "id": 0,
                        "start": 0.0,
                        "end": 0.0,
                        "text": text
                    })
            else:
                text = ""
                segments = []
            
            language = "zh"  # Paraformer-zhæ˜¯ä¸­æ–‡æ¨¡å‹
            logging.info(f"è½¬å†™å®Œæˆï¼Œæ£€æµ‹åˆ°è¯­è¨€: {language}")
            logging.info(f"è½¬å½•æ®µè½æ•°: {len(segments)}")
            
            # è¯´è¯äººè¯†åˆ«ï¼ˆå¯é€‰ï¼‰
            diarization = None
            if self.diarization_pipeline is not None:
                logging.info("å¼€å§‹è¯´è¯äººè¯†åˆ«...")
                try:
                    # ä½¿ç”¨æ–°çš„Paraformeræ¨¡å‹è¿›è¡Œè¯´è¯äººè¯†åˆ«
                    diarization_result = self.diarization_pipeline.generate(input=wav_path, batch_size_s=60, batch_size_threshold_s=60)
                    
                    # å¤„ç†è¯†åˆ«ç»“æœ
                    if diarization_result and len(diarization_result) > 0:
                        diarization = diarization_result[0] if "spk_segment" in diarization_result[0] else None
                        if diarization:
                            logging.info("è¯´è¯äººè¯†åˆ«å®Œæˆ")
                        else:
                            logging.info("è¯´è¯äººè¯†åˆ«å®Œæˆ - æœªæ£€æµ‹åˆ°è¯´è¯äºº")
                    else:
                        logging.info("è¯´è¯äººè¯†åˆ«å®Œæˆ - æœªæ£€æµ‹åˆ°è¯´è¯äºº")
                        
                except Exception as e:
                    logging.warning(f"è¯´è¯äººè¯†åˆ«å¤±è´¥: {str(e)}")
                    logging.warning("ç»§ç»­å¤„ç†ï¼Œè·³è¿‡è¯´è¯äººè¯†åˆ«")
            else:
                logging.info("è·³è¿‡è¯´è¯äººè¯†åˆ«ï¼ˆæ¨¡å‹æœªåŠ è½½ï¼‰")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.unlink(wav_path)
            except:
                pass
                
            return {
                "transcript": segments,
                "speakers": diarization,
                "language": language,
                "video_path": video_path,
                "processed_at": datetime.now().isoformat()
            }
            
        except Exception as e:
            logging.error(f"ASRå¤„ç†å¤±è´¥: {str(e)}")
            # å°è¯•æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                if 'wav_path' in locals():
                    os.unlink(wav_path)
            except:
                pass
            raise

    def process_videos(self, video_dir: str) -> list:
        """æ‰¹é‡å¤„ç†è§†é¢‘ç›®å½•"""
        video_dir = Path(video_dir)
        if not video_dir.exists():
            raise FileNotFoundError(f"è§†é¢‘ç›®å½•ä¸å­˜åœ¨: {video_dir}")
            
        # æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶
        video_extensions = ['.mp4', '.mov', '.avi', '.mkv', '.wmv', '.flv', '.webm']
        video_files = []
        for ext in video_extensions:
            video_files.extend(video_dir.glob(f"*{ext}"))
            
        if not video_files:
            raise FileNotFoundError(f"æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶: {video_dir}")
            
        logging.info(f"æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
        
        results = []
        for video_file in video_files:
            try:
                result = self.devour_video(str(video_file))
                results.append(result)
                logging.info(f"âœ… å®Œæˆ: {video_file.name}")
            except Exception as e:
                logging.error(f"âŒ å¤±è´¥: {video_file.name} - {str(e)}")
                continue
                
        return results
        
    def save_results(self, results: list, output_file: str):
        """ä¿å­˜å¤„ç†ç»“æœåˆ°JSONæ–‡ä»¶"""
        # è½¬æ¢speakerså¯¹è±¡ä¸ºå¯åºåˆ—åŒ–æ ¼å¼
        for result in results:
            if 'speakers' in result and result['speakers'] is not None:
                # å¤„ç†æ–°çš„Paraformeræ¨¡å‹çš„è¯´è¯äººè¯†åˆ«ç»“æœ
                if isinstance(result['speakers'], dict) and 'spk_segment' in result['speakers']:
                    speakers_data = []
                    try:
                        # å¤„ç†è¯´è¯äººåˆ†æ®µä¿¡æ¯
                        for segment in result['speakers']['spk_segment']:
                            speakers_data.append({
                                "speaker": segment.get('spk', 'UNKNOWN'),
                                "start": float(segment.get('start', 0)),
                                "end": float(segment.get('end', 0)),
                                "duration": float(segment.get('end', 0) - segment.get('start', 0))
                            })
                        result['speakers'] = speakers_data
                    except Exception as e:
                        logging.warning(f"è¯´è¯äººæ•°æ®è½¬æ¢å¤±è´¥: {str(e)}")
                        result['speakers'] = str(result['speakers'])
                # ä¿æŒå¯¹æ—§æ ¼å¼çš„å…¼å®¹æ€§
                elif hasattr(result['speakers'], 'itertracks'):
                    # æå–è¯´è¯äººæ—¶é—´è½´ä¿¡æ¯ä¸ºç»“æ„åŒ–æ•°æ®
                    speakers_data = []
                    try:
                        for turn, _, speaker in result['speakers'].itertracks(yield_label=True):
                            speakers_data.append({
                                "speaker": speaker,
                                "start": float(turn.start),
                                "end": float(turn.end),
                                "duration": float(turn.end - turn.start)
                            })
                        result['speakers'] = speakers_data
                    except Exception as e:
                        logging.warning(f"è¯´è¯äººæ•°æ®è½¬æ¢å¤±è´¥: {str(e)}")
                        result['speakers'] = str(result['speakers'])
                else:
                    # å¦‚æœæ˜¯å…¶ä»–æ ¼å¼ï¼Œç›´æ¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                    result['speakers'] = str(result['speakers'])
            
            # ç»Ÿè®¡è½¬å½•æ–‡æœ¬è´¨é‡æŒ‡æ ‡
            if 'transcript' in result and result['transcript']:
                total_text = " ".join([segment.get('text', '') for segment in result['transcript']])
                result['text_stats'] = {
                    "total_segments": len(result['transcript']),
                    "total_words": len(total_text.split()),
                    "total_chars": len(total_text),
                    "avg_segment_duration": sum([seg.get('end', 0) - seg.get('start', 0) for seg in result['transcript']]) / len(result['transcript']) if result['transcript'] else 0
                }
                
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        logging.info(f"ç»“æœå·²ä¿å­˜åˆ°: {output_file}")


if __name__ == "__main__":
    # æµ‹è¯•ASRå¼•æ“
    logging.info("ğŸ½ï¸ VideoDevour ASR Funasrå¼•æ“æµ‹è¯•å¼€å§‹")
    
    try:
        # åˆå§‹åŒ–ASRå¼•æ“
        asr = VideoDevourASRFunasr()
        
        # å¤„ç†è§†é¢‘ç›®å½•
        # Get the project root directory (assuming this file is in backend/devour)
        project_root = Path(__file__).resolve().parent.parent.parent
        video_dir = project_root / "input_video"
        results = asr.process_videos(str(video_dir))
        
        # ä¿å­˜ç»“æœ
        output_file = project_root / "output" / "asr_results_paraformer.json"
        output_file.parent.mkdir(parents=True, exist_ok=True)
        asr.save_results(results, str(output_file))
        
        # æ‰“å°æ‘˜è¦
        logging.info(f"\nğŸ“Š å¤„ç†æ‘˜è¦:")
        logging.info(f"âœ… æˆåŠŸå¤„ç†: {len(results)} ä¸ªè§†é¢‘")
        
        total_segments = 0
        total_words = 0
        total_chars = 0
        
        for i, result in enumerate(results, 1):
            logging.info(f"  {i}. {Path(result['video_path']).name}")
            logging.info(f"     è¯­è¨€: {result['language']}")
            logging.info(f"     æ®µè½æ•°: {len(result['transcript'])}")
            
            # ç»Ÿè®¡æ–‡æœ¬ä¿¡æ¯
            if 'text_stats' in result:
                stats = result['text_stats']
                total_segments += stats['total_segments']
                total_words += stats['total_words'] 
                total_chars += stats['total_chars']
                logging.info(f"     å­—æ•°: {stats['total_words']}, å­—ç¬¦æ•°: {stats['total_chars']}")
            
            # è¯´è¯äººä¿¡æ¯
            if result.get('speakers'):
                if isinstance(result['speakers'], list):
                    unique_speakers = len(set(s['speaker'] for s in result['speakers']))
                    logging.info(f"     è¯´è¯äºº: {unique_speakers} ä½")
                else:
                    logging.info(f"     è¯´è¯äºº: æ•°æ®å¯ç”¨")
        
        # æ€»ä½“ç»Ÿè®¡
        if total_segments > 0:
            logging.info(f"\nğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
            logging.info(f"     æ€»æ®µè½æ•°: {total_segments}")
            logging.info(f"     æ€»å­—æ•°: {total_words}")
            logging.info(f"     æ€»å­—ç¬¦æ•°: {total_chars}")
            logging.info(f"     å¹³å‡æ®µè½é•¿åº¦: {total_chars/total_segments:.1f} å­—ç¬¦")
            
    except Exception as e:
        logging.error(f"æµ‹è¯•å¤±è´¥: {str(e)}")
        exit(1)